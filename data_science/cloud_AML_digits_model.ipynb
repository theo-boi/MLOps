{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before...\n",
    "=========\n",
    "\n",
    "We developed a model for digits classification in `MLOps/data_science/working/data_science_digits_model.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now\n",
    "===\n",
    "\n",
    "We migrate to the cloud by adapting the previous notebook for **Azure Machine Learning**.\n",
    "\n",
    "This notebook should be run in the **Azure Machine Learning Studio** for real easy use.\n",
    "Note that it is possible to run it outside of AML Studio if you install Azure ML SDK using `pip install azureml-sdk` and configure your credentials in **Authentification**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1679323497102
    }
   },
   "outputs": [],
   "source": [
    "# Handle to the workspace\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1679323497309
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "    resource_group_name=\"<RESOURCE_GROUP>\",\n",
    "    workspace_name=\"<AZUREML_WORKSPACE_NAME>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1679323498534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have a cluster named cpu-cluster, we'll reuse it as is.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "# Name assigned to the compute cluster\n",
    "cpu_compute_target = \"cpu-cluster\"\n",
    "\n",
    "try:\n",
    "    # let's see if the compute target already exists\n",
    "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
    "    print(\n",
    "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
    "    )\n",
    "\n",
    "except Exception:\n",
    "    print(\"Creating a new cpu compute target...\")\n",
    "\n",
    "    # Let's create the Azure ML compute object with the intended parameters\n",
    "    cpu_cluster = AmlCompute(\n",
    "        name=cpu_compute_target,\n",
    "        # Azure ML Compute is the on-demand VM service\n",
    "        type=\"amlcompute\",\n",
    "        # VM Family\n",
    "        size=\"STANDARD_F4S_V2\", #\"STANDARD_DS2_V2\", #STANDARD_DS3_V2\n",
    "        # Minimum running nodes when there is no job running\n",
    "        min_instances=0,\n",
    "        # Nodes in cluster\n",
    "        max_instances=1,\n",
    "        # How many seconds will the node running after the job termination\n",
    "        idle_time_before_scale_down=180,\n",
    "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
    "        tier=\"Dedicated\",\n",
    "    )\n",
    "    print(\n",
    "        f\"AMLCompute with name {cpu_cluster.name} will be created, with compute size {cpu_cluster.size}\"\n",
    "    )\n",
    "    # Now, we pass the object to MLClient's create_or_update method\n",
    "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1679323499374
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dependencies_dir = \"./dependencies\"\n",
    "os.makedirs(dependencies_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./dependencies/conda.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {dependencies_dir}/conda.yml\n",
    "name: model-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - numpy=1.21.2\n",
    "  - tensorflow=2.6.0\n",
    "  - tensorflow-estimator=2.6.0\n",
    "  - keras=2.6.0\n",
    "  - pip=21.2.4\n",
    "  - scipy=1.7.1\n",
    "  - pandas>=1.1,<1.2\n",
    "  - pip:\n",
    "    - inference-schema[numpy-support]==1.3.0\n",
    "    - xlrd==2.0.1\n",
    "    - mlflow== 1.26.1\n",
    "    - azureml-mlflow==1.42.0\n",
    "    - psutil>=5.8,<5.9\n",
    "    - tqdm>=4.59,<4.60\n",
    "    - ipykernel~=6.0\n",
    "    - matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1679323503608
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment with name cv_dl is registered to workspace, the environment version is 8\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "custom_env_name = \"cv_dl\"\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=custom_env_name,\n",
    "    description=\"Custom environment for tutorial of MLOps\",\n",
    "    tags={\"tensorflow\": \"2.6.0\"},\n",
    "    conda_file=os.path.join(dependencies_dir, \"conda.yml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\",\n",
    ")\n",
    "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1679323503777
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_src_dir = \"./working\"\n",
    "os.makedirs(train_src_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./working/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {train_src_dir}/main.py\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow.keras\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Lambda, Dense, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization, Convolution2D , MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train\", type=str, help=\"path to train data\")\n",
    "    parser.add_argument(\"--test\", type=str, help=\"path to test data\")\n",
    "    parser.add_argument(\"--learning_rate\", required=False, default=0.001, type=float)\n",
    "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
    "    args = parser.parse_args()\n",
    "   \n",
    "    # Start Logging\n",
    "    mlflow.start_run()\n",
    "\n",
    "    # enable autologging\n",
    "    mlflow.tensorflow.autolog()\n",
    "\n",
    "    ###################\n",
    "    #<prepare the data>\n",
    "    ###################\n",
    "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
    "\n",
    "    print(\"train data:\", args.train)\n",
    "    print(\"train data:\", args.test)\n",
    "\n",
    "    # create the training & test sets, skipping the header row with [1:]\n",
    "    train = pd.read_csv(args.train)\n",
    "    test = pd.read_csv(args.test)\n",
    "\n",
    "    # Extracting the label column\n",
    "    X_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\n",
    "    y_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\n",
    "    \n",
    "    X_test = test.values.astype('float32')\n",
    "\n",
    "    # Convert train datset to (num_images, img_rows, img_cols, colour_channel_gray) format\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n",
    "\n",
    "    mlflow.log_metric(\"num_features\", X_train.shape[1]*X_train.shape[2])\n",
    "\n",
    "    mean_px = X_train.mean().astype(np.float32)\n",
    "    std_px = X_train.std().astype(np.float32)\n",
    "\n",
    "    def standardize(x): \n",
    "        return (x-mean_px)/std_px\n",
    "\n",
    "    y_train= to_categorical(y_train)\n",
    "    \n",
    "    mlflow.log_metric(\"num_samples\", y_train.shape[1])\n",
    "    ####################\n",
    "    #</prepare the data>\n",
    "    ####################\n",
    "\n",
    "    ##################\n",
    "    #<train the model>\n",
    "    ##################\n",
    "    # fix random seed for reproducibility\n",
    "    seed = 43\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    batch_size = 64\n",
    "    gen = ImageDataGenerator()\n",
    "    batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "    def get_bn_model():\n",
    "        model = Sequential([\n",
    "            Lambda(standardize, input_shape=(28,28,1)),\n",
    "            Convolution2D(32,(3,3), activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            Convolution2D(32,(3,3), activation='relu'),\n",
    "            MaxPooling2D(),\n",
    "            BatchNormalization(axis=1),\n",
    "            Convolution2D(64,(3,3), activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            Convolution2D(64,(3,3), activation='relu'),\n",
    "            MaxPooling2D(),\n",
    "            Flatten(),\n",
    "            BatchNormalization(),\n",
    "            Dense(512, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(10, activation='softmax')\n",
    "            ])\n",
    "        model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    model = get_bn_model()\n",
    "    model.optimizer.lr = args.learning_rate\n",
    "\n",
    "    print(f\"Training with data of shape {X_train.shape}\")\n",
    "\n",
    "    model.fit(batches, steps_per_epoch=len(batches), epochs=5)\n",
    "    ###################\n",
    "    #</train the model>\n",
    "    ###################\n",
    "    \n",
    "    # Stop Logging\n",
    "    mlflow.end_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Azure ML training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1679323504436
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "registered_model_name = \"digits_model\"\n",
    "\n",
    "job = command(\n",
    "    inputs=dict(\n",
    "        train=Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"./input/train.csv\",\n",
    "        ),\n",
    "        test=Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"./input/test.csv\",\n",
    "        ),\n",
    "        learning_rate=0.001,\n",
    "        registered_model_name=registered_model_name,\n",
    "    ),\n",
    "    code=\"./working/\",  # location of source code\n",
    "    command=\"python main.py --train ${{inputs.train}} --test ${{inputs.test}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}\",\n",
    "    environment=\"cv_dl@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"train_model_mnist\",\n",
    "    display_name=\"digits\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1679323512081
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading working (0.01 MBs): 100%|██████████| 5004/5004 [00:00<00:00, 93741.70it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>train_model_mnist</td><td>purple_circle_pv1n6f4sqq</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/purple_circle_pv1n6f4sqq?wsid=/subscriptions/89d37bc4-f3cb-4d86-850f-b02b15def2b5/resourcegroups/theo.boisseau-rg/workspaces/mlops&amp;tid=16150599-ebb0-4fcf-94a5-6010823c7bd5\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'type': 'command', 'status': 'Starting', 'log_files': None, 'name': 'purple_circle_pv1n6f4sqq', 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': 'e33fcf7c-6883-4f44-b439-596bf15788c9'}, 'id': '/subscriptions/89d37bc4-f3cb-4d86-850f-b02b15def2b5/resourceGroups/theo.boisseau-rg/providers/Microsoft.MachineLearningServices/workspaces/mlops/jobs/purple_circle_pv1n6f4sqq', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/mlopscompute/code/Users/theo.boisseau', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fe01ce96830>, 'serialize': <msrest.serialization.Serializer object at 0x7fe01ce96c80>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'digits', 'experiment_name': 'train_model_mnist', 'compute': 'cpu-cluster', 'services': {'Tracking': <azure.ai.ml.entities._job.job_service.JobService object at 0x7fe01cfa0a30>, 'Studio': <azure.ai.ml.entities._job.job_service.JobService object at 0x7fe01ce95d50>}, 'comment': None, 'job_inputs': {'train': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/1486a642f9f48684ec8ad3c2208f48e5/train.csv', 'mode': 'ro_mount'}, 'test': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/4f7ed562b2ffefa48688a2e24f3819b4/test.csv', 'mode': 'ro_mount'}, 'learning_rate': '0.001', 'registered_model_name': 'digits_model'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.purple_circle_pv1n6f4sqq', 'mode': 'rw_mount'}}, 'inputs': {'train': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fe01ce94f10>, 'test': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fe01ce94b80>, 'learning_rate': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fe01ce94340>, 'registered_model_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fe01ce94370>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7fe01ce96b60>}, 'component': CommandComponent({'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'name': 'purple_circle_pv1n6f4sqq', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fe01ce96830>, 'serialize': <msrest.serialization.Serializer object at 0x7fe01ce95450>, 'command': 'python main.py --train ${{inputs.train}} --test ${{inputs.test}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}', 'code': '/subscriptions/89d37bc4-f3cb-4d86-850f-b02b15def2b5/resourceGroups/theo.boisseau-rg/providers/Microsoft.MachineLearningServices/workspaces/mlops/codes/79fce459-f96d-4a3f-a5c9-a19d502de9e4/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/89d37bc4-f3cb-4d86-850f-b02b15def2b5/resourceGroups/theo.boisseau-rg/providers/Microsoft.MachineLearningServices/workspaces/mlops/environments/cv_dl/versions/8', 'distribution': None, 'resources': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'digits', 'is_deterministic': True, 'inputs': {'train': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/1486a642f9f48684ec8ad3c2208f48e5/train.csv', 'mode': 'ro_mount'}, 'test': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/4f7ed562b2ffefa48688a2e24f3819b4/test.csv', 'mode': 'ro_mount'}, 'learning_rate': {'type': 'string', 'default': '0.001'}, 'registered_model_name': {'type': 'string', 'default': 'digits_model'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.purple_circle_pv1n6f4sqq', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': <azure.ai.ml.entities._job.job_service.JobService object at 0x7fe01cfa0a30>, 'Studio': <azure.ai.ml.entities._job.job_service.JobService object at 0x7fe01ce95d50>}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fe01ce96830>}, 'instance_id': 'eafd8a3c-5051-4860-9f5b-af036db8ae7b', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'cv_dl:8', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'swept': False})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.create_or_update(job)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
