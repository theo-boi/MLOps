{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d2c865-7a16-45a5-ac54-46e195dae507",
   "metadata": {},
   "source": [
    "Before...\n",
    "=========\n",
    "\n",
    "We developed a model for digits classification in `MLOps/data_science/working/data_science_digits_model.ipynb`.\n",
    "\n",
    "We migrated to the cloud by adapting the notebook for **Azure Machine Learning** in `MLOps/data_science/cloud_AML_digits_model.ipynb`.\n",
    "\n",
    "We downloaded the artifact from the Azure ML training job output and saved it in this repository under the name `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3585e5-40c5-4e98-a6c8-6121e5aaa8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_science_dir = os.path.join('../', \"data_science\")\n",
    "aml_job_output = \"model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a072f5e-a39f-46ae-8127-55de0c93d6ca",
   "metadata": {},
   "source": [
    "Now\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd7bb3-61e7-4fa9-b699-d3825465ed5d",
   "metadata": {},
   "source": [
    "The problem we face\n",
    "-------------------\n",
    "\n",
    "To deploy our model on a Azure ML **Real-time Endpoint**, we needed a virtual machine big enough to contain the deep neural network. Not a *very small* but a *small* VM would have been enough, such as Standard_F4s_v2 or Standard_DS2_v2.\n",
    "However, we did not have enough **Endpoint quota** in our *Azure for Students* subscription for deploying the model on such a VM.\n",
    "\n",
    "Since we cannot deploy our model on the cloud, we simulate a production environment in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7ed4dc-c295-48d2-909e-5bf4804bff0e",
   "metadata": {},
   "source": [
    "The artifact from the AzureML training job output...\n",
    "----------------------------------------------------\n",
    "\n",
    "It contains all the necessary data for reproductibility:\n",
    "- environment and requirements files\n",
    "- details about the ML framework (scikit-learn, tensorflow, pytorch...)\n",
    "- serialized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecbbd55b-79b0-4048-98b4-8bffab2685da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\\conda.yaml <- ENVIRONMENT FILE\n",
      "model\\MLmodel\n",
      "model\\python_env.yaml <- ENVIRONMENT FILE\n",
      "model\\requirements.txt\n",
      "model\\_summary.txt\n",
      "model\\data\\keras_module.txt\n",
      "model\\data\\save_format.txt\n",
      "model\\data\\model\\keras_metadata.pb\n",
      "model\\data\\model\\saved_model.pb <- SERIALIZED MODEL\n",
      "model\\data\\model\\variables\\variables.data-00000-of-00001\n",
      "model\\data\\model\\variables\\variables.index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def walkAmlJobOutput():\n",
    "    for path, currentDirectory, files in os.walk(aml_job_output):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(path, file)\n",
    "            if os.sep+'.' not in filepath: #hide hidden files\n",
    "                yield file, filepath\n",
    "\n",
    "conda_file = None\n",
    "for file, filepath in walkAmlJobOutput():\n",
    "    print(filepath, end='')\n",
    "    if '.yaml' in file:\n",
    "        if file == \"conda.yaml\": conda_file = filepath\n",
    "        print(\" <- ENVIRONMENT FILE\", end='')\n",
    "    if file == \"saved_model.pb\":\n",
    "        print(\" <- SERIALIZED MODEL\", end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d780bdc-3ccf-4d42-be51-e8ff2d7f3ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to Conda environment file: model\\conda.yaml\n"
     ]
    }
   ],
   "source": [
    "print(f\"Path to Conda environment file: {conda_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca1899-484a-44d8-a788-36afff3d9a08",
   "metadata": {},
   "source": [
    "## Install the right environment to run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03e8f12-2bd5-4aea-afc4-b7065fbbfc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels:\n",
      "- conda-forge\n",
      "dependencies:\n",
      "- python=3.8.15\n",
      "- pip<=21.2.4\n",
      "- pip:\n",
      "  - mlflow\n",
      "  - cffi==1.15.1\n",
      "  - keras==2.6.0\n",
      "  - pillow==9.4.0\n",
      "  - scipy==1.7.1\n",
      "  - tensorflow==2.6.0\n",
      "name: mlflow-env\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(conda_file, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b0c2d-b3c2-4554-8b3c-de1e9673ec23",
   "metadata": {},
   "source": [
    "- Open your terminal\n",
    "- Install the conda environment using `conda env create --name mlops-model-env --file <path/to/conda_file>`\n",
    "- Activate it with `conda activate mlops-model-env`\n",
    "- Install your favorite package for using notebooks\n",
    "- Reopen this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33fabca-9da8-4b8a-954e-a0654359d7dd",
   "metadata": {},
   "source": [
    "Additionally, install opencv using `conda install -c conda-forge opencv` for the deployement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c3fa4-192b-45b5-82d2-54a48be3828e",
   "metadata": {},
   "source": [
    "Production simulation setup\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8131c0e1-b14b-45e4-b04e-47cf15f33bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "prod_dir = \"./sample_requests\"\n",
    "os.makedirs(prod_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96e3d551-6359-4098-bcc7-16160000b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from working.dummy_server import DummyServer\n",
    "import pandas as pd\n",
    "\n",
    "original_data_quantity = 50\n",
    "\n",
    "mnist_data = pd.read_csv(os.path.join(data_science_dir, \"input\", \"test.csv\"))\n",
    "mnist_data = mnist_data.tail(original_data_quantity)\n",
    "\n",
    "prod_data = mnist_data\n",
    "\n",
    "server = DummyServer(prod_data, prod_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eaf48af-d1c7-4c69-b0cd-2ff0d0e0272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "server.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890998c1-d376-4001-ba0a-315b95f9ded0",
   "metadata": {},
   "source": [
    "## Deploy the MLFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "566b1213-8b7d-47dc-b4c3-1b7858415247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "prod_src_dir = \"./working\"\n",
    "os.makedirs(prod_src_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "161595ae-6569-42f7-87aa-e9b4fcffc979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./working/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {prod_src_dir}/score.py\n",
    "import os, json, random, mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import StringIO\n",
    "from mlflow.pyfunc.scoring_server import predictions_to_json\n",
    "\n",
    "\n",
    "# Set up MLflow tracking\n",
    "experiment_name = \"inference\"+str(random.randint(10000,100000))\n",
    "mlflow.set_experiment(experiment_name)\n",
    "client = mlflow.MlflowClient()\n",
    "\n",
    "\n",
    "def init(model_path):\n",
    "    global model\n",
    "    global input_schema\n",
    "    # \"model\" is the path of the mlflow artifacts when the model was registered. For automl\n",
    "    # models, this is generally \"mlflow-model\".\n",
    "    model = mlflow.pyfunc.load_model(model_path)\n",
    "    input_schema = model.metadata.get_input_schema()\n",
    "    os.environ['MLFLOW_TRACKING_FORCE_NO_GIT'] = '1'\n",
    "    os.environ['GIT_PYTHON_REFRESH'] = '0'\n",
    "\n",
    "    \n",
    "    \n",
    "def parse_json_input(json_data):\n",
    "    json_df = pd.read_json(json.dumps(json_data['dataframe_split']), orient='split')\n",
    "    data = json_df.values.astype('float32')\n",
    "    data = data.reshape(1, 28, 28, 1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "\n",
    "def run(raw_data):\n",
    "    json_data = json.loads(raw_data)\n",
    "    if 'dataframe_split' not in json_data.keys():\n",
    "        raise Exception(\"Request must contain a top level key named 'dataframe_split'\")\n",
    "\n",
    "    data = parse_json_input(json_data)\n",
    "    \n",
    "    # Log the data as an artifact\n",
    "    with mlflow.start_run() as run:\n",
    "        run_id = run.info.run_id\n",
    "        Image.fromarray(data.reshape(28,28).astype(np.uint8)).save('data.png')\n",
    "        mlflow.log_artifact(\"data.png\")\n",
    "    \n",
    "    # Make predictions and log them\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        predictions = model.predict(data)\n",
    "        \n",
    "        best_prediction = int(np.argmax(predictions, axis=1))\n",
    "        best_proba = np.max(predictions, axis=1)\n",
    "        worst_proba = np.min(predictions, axis=1)\n",
    "        \n",
    "        # log predicted probabilities as metrics\n",
    "        for i, p in enumerate(predictions[0]):\n",
    "            mlflow.log_metric(f'probability_class_{i}', p)\n",
    "        \n",
    "        # Log the predictions as an artifact\n",
    "        with open(\"best_pred.txt\", \"w\") as f:\n",
    "            f.write(str(best_prediction))\n",
    "        mlflow.log_artifact(\"best_pred.txt\")\n",
    "\n",
    "        # Log any anomalous predictions as a metric\n",
    "        if best_proba < 0.9:\n",
    "            mlflow.log_metric(\"anomalous_pred_proba\", best_proba, step=i)\n",
    "        if worst_proba > 0.1:\n",
    "            mlflow.log_metric(\"anomalous_pred_proba\", worst_proba, step=i)\n",
    "        avg_preds = average(predictions[0])\n",
    "        if round(avg_preds, 1) != 0.1:\n",
    "            mlflow.log_metric('anomalous_avg_probas', avg_preds)\n",
    "        sum_preds = sum(predictions[0])\n",
    "        if round(sum_preds) != 1:\n",
    "            mlflow.log_metric('anomalous_sum_probas', sum_preds)\n",
    "        \n",
    "    result = StringIO()\n",
    "    predictions_to_json(best_prediction, result)\n",
    "    return result.getvalue(), data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe164c89-a69b-4f28-9a9d-cb5f73aef5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/27 11:00:57 INFO mlflow.tracking.fluent: Experiment with name 'inference43725' does not exist. Creating a new experiment.\n",
      "C:\\Users\\boiss\\anaconda3\\envs\\mlops-model-env\\lib\\site-packages\\keras\\backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow.pyfunc.loaded_model:\n",
      "  artifact_path: model\n",
      "  flavor: mlflow.keras\n",
      "  run_id: khaki_parsnip_0nh4r3mgw2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import working.score as score\n",
    "\n",
    "score.init(aml_job_output)\n",
    "\n",
    "print(score.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d842f0-fd1b-4ba3-98a2-f26780a3514f",
   "metadata": {},
   "source": [
    "**If you had an error loading the serialized model, it is probably due to Azure using another version of Python... See `python_env.yaml`.**\n",
    "\n",
    "Try downgrading protobuf using `pip install protobuf==3.20.*` in a terminal and restarting the kernel of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeca7e7f-b523-413a-a6f6-4ef6dee13fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/27 11:01:00 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Unknown model type: <class 'mlflow.pyfunc.PyFuncModel'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m predictions_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m raw_data \u001b[38;5;129;01min\u001b[39;00m server\u001b[38;5;241m.\u001b[39mdo_GET():\n\u001b[1;32m----> 3\u001b[0m     predictions_data\u001b[38;5;241m.\u001b[39mappend(\u001b[43mscore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\workspaces\\Conda\\MLOps\\production\\working\\score.py:81\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(raw_data)\u001b[0m\n\u001b[0;32m     78\u001b[0m         mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manomalous_sum_probas\u001b[39m\u001b[38;5;124m'\u001b[39m, sum_preds)\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# Log your model to MLflow\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m result \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[0;32m     84\u001b[0m predictions_to_json(best_prediction, result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mlops-model-env\\lib\\site-packages\\mlflow\\tensorflow\\__init__.py:222\u001b[0m, in \u001b[0;36mlog_model\u001b[1;34m(model, artifact_path, custom_objects, conda_env, code_paths, signature, input_example, registered_model_name, await_registration_for, pip_requirements, extra_pip_requirements, saved_model_kwargs, keras_model_kwargs, metadata)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[38;5;241m.\u001b[39mformat(package_name\u001b[38;5;241m=\u001b[39mFLAVOR_NAME))\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_model\u001b[39m(\n\u001b[0;32m    126\u001b[0m     model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    140\u001b[0m ):\n\u001b[0;32m    141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m    Log a TF2 core model (inheriting tf.Module) or a Keras model in MLflow Model format.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m             metadata of the logged model.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensorflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43msaved_model_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msaved_model_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeras_model_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeras_model_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mlops-model-env\\lib\\site-packages\\mlflow\\models\\model.py:551\u001b[0m, in \u001b[0;36mModel.log\u001b[1;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m run_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mfluent\u001b[38;5;241m.\u001b[39m_get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m    550\u001b[0m mlflow_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(artifact_path\u001b[38;5;241m=\u001b[39martifact_path, run_id\u001b[38;5;241m=\u001b[39mrun_id, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n\u001b[1;32m--> 551\u001b[0m \u001b[43mflavor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mfluent\u001b[38;5;241m.\u001b[39mlog_artifacts(local_path, mlflow_model\u001b[38;5;241m.\u001b[39martifact_path)\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mlops-model-env\\lib\\site-packages\\mlflow\\tensorflow\\__init__.py:459\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, path, conda_env, code_paths, mlflow_model, custom_objects, signature, input_example, pip_requirements, extra_pip_requirements, saved_model_kwargs, keras_model_kwargs, metadata)\u001b[0m\n\u001b[0;32m    454\u001b[0m     flavor_options \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_model_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_dir_subpath,\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: _MODEL_TYPE_TF2_MODULE,\n\u001b[0;32m    457\u001b[0m     }\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown model type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    461\u001b[0m \u001b[38;5;66;03m# update flavor info to mlflow_model\u001b[39;00m\n\u001b[0;32m    462\u001b[0m mlflow_model\u001b[38;5;241m.\u001b[39madd_flavor(FLAVOR_NAME, code\u001b[38;5;241m=\u001b[39mcode_dir_subpath, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflavor_options)\n",
      "\u001b[1;31mMlflowException\u001b[0m: Unknown model type: <class 'mlflow.pyfunc.PyFuncModel'>"
     ]
    }
   ],
   "source": [
    "predictions_data = []\n",
    "for raw_data in server.do_GET():\n",
    "    predictions_data.append(score.run(raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e231777-ea3e-4dfe-a609-335ee08fd4d2",
   "metadata": {},
   "source": [
    "Analysis\n",
    "--------\n",
    "\n",
    "Now, you can visualise the output below, but you can also run `mlflow ui` in your terminal and analyse the logged metrics on the local website!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc26c42-ed0c-4183-9d25-8048e75b7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from working.visualisation import plot\n",
    "\n",
    "plot(predictions_data, last=15, hspace=0.3, fig_size=(16, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574373f-0955-4d5c-af60-54fc573e6c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
